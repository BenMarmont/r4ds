---
title: "7_Factors_Dates_Times"
author: "BM"
date: "24/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(nycflights13)
gss_cat
library(lubridate)
```

# Workshop 7: Factors, Dates and Times 
This workshop covers chapters 15 and 16 of R4DS (online version.)

In R factors work with categorical variables, that is variables with a known set of possible values. They can also be used to display character vectors in non-alphabetical order.

The cheat sheet for factors is called forcats (anagram of factors)

# Factors
## Creating factors

```{r}
x1 <- c("Dec", "Apr", "Jan", "Mar")
x2 <- c("Dec", "Apr", "Jam", "Mar")
sort(x1)

month_levels <- c(
  "Jan", "Feb", "Mar", "Apr", "May", "Jun",
  "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"
)

y1 <- factor(x1, levels = month_levels)

sort(y1)

y2 <- factor(x2, levels = month_levels)
y2
```
The levels sets out the order of the factor, without them they will be delivered alphabetically.
In the above example the  Jam not in the levels was silently converted to an NA. You can check via

```{r}
y2 <- parse_factor(x2, levels = month_levels)

```
Which yields the issue. You can also set the levels in order of appearance in the data. In the below example the first sets in the levels first while the latter sets it after.
```{r}
f1 <- factor(x1, levels = unique(x1))
f1
#> [1] Dec Apr Jan Mar
#> Levels: Dec Apr Jan Mar

f2 <- x1 %>% factor() %>% fct_inorder()
f2
#> [1] Dec Apr Jan Mar
#> Levels: Dec Apr Jan Mar
```
You can find the levels in data with
```{r}
levels(f2)
```

## GSS (General Social Survery)
```{r}
gss_cat %>% 
  count(race)

ggplot(gss_cat, aes(x = race)) +
  geom_bar()
ggplot(gss_cat, aes(x = race)) +
  geom_bar() + 
  scale_x_discrete(drop = FALSE)
```
GGPLOT will drop levels with no data. You can prevent this with scale_x_discrete(drop = false). This shows that there was a NA option that no one selected in the survey.

### Exercises 15.3.1
#### 1. 
Report income
```{r}
?gss_cat
ggplot(gss_cat, aes(x = rincome)) + 
  geom_bar() 

ggplot(gss_cat, aes(x = rincome)) + 
  geom_bar() +
  coord_flip()
  
  
```
This shows the distribution of reported income amongst survey participants. Hard to interpret due to overlapping income values. This could be addressed by a co-ord flip. When flipping the coords I forgot the (), took a while to troubleshoot.

#### 2.
Most common religion and party affiliation
```{r}
ggplot(gss_cat, aes(x = relig)) +
  geom_bar() + 
  scale_x_discrete(drop = FALSE) +
  coord_flip()

ggplot(gss_cat, aes(x = partyid)) +
  geom_bar() + 
  scale_x_discrete(drop = FALSE) +
  coord_flip()
```
The most common religion is protestant while the highest reported party identification is Independent

#### 3.
Exploring religions with denominations. This shows that Protestants have denominations but other religions do. Can also be done visually.
```{r}
gss_cat %>% 
  count(relig, denom) %>% 
  arrange(desc(n))

```
### Changing Factor Order
```{r}
relig_summary <- gss_cat %>% 
  group_by(relig) %>% 
  summarise(
    age = mean(age, na.rm = TRUE),
    tvhours = mean(tvhours, na.rm = TRUE),
    n = n())

ggplot(relig_summary, aes(x = tvhours, y = relig)) +
  geom_point()
```

This graph is hard to interpret, no clear pattern. So we reorder
### fct_reorder
Needs:factor you want to reorder, x numberic vector as a basis for reordering, optional function (default is median)
```{r}
ggplot(relig_summary, aes(x = tvhours, y = fct_reorder(relig, tvhours))) +
  geom_point()
```

This shows that Eastern religions tend to watch less tv than Western religions. Keeping in mind that this survey is self reported. Additionally, it may be better to mutate the factor reorder before the ggplot, simplifying the GGPLOT call.
```{r}
relig_summary %>% 
  mutate(relig = fct_reorder(relig, tvhours)) %>% 
  ggplot(aes(x = tvhours, y = relig)) + 
  geom_point()
```

Do older people have more income?
The following code shows age and income, but just because you can do something, doesn't mean you should. The second graph illstrates a better graphic with less code. 
```{r}
rincome_summary <- gss_cat %>% 
  group_by(rincome) %>% 
  summarise(
    age = mean(age, na.rm = TRUE),
    tvhours = mean(tvhours, na.rm = TRUE),
    n = n()
  )

rincome_summary

ggplot(rincome_summary, aes(x = age, y = fct_reorder(rincome, age)))+
  geom_point()

```

```{r}
ggplot(rincome_summary, aes(age, rincome)) + 
  geom_point()
```

### Re-ordering for line plots
```{r}
by_age <- gss_cat %>% 
  filter(!is.na(age)) %>% 
  count(age, marital) %>% 
  group_by(age) %>% 
  mutate(prop = n / sum(n))

by_age

ggplot(by_age, aes(age, prop, colour = marital)) +
  geom_line(na.rm = TRUE)

```
recalling that ! means does not, so those values not = NA. The marital status by colour is hard to read so.

```{r}
ggplot(by_age, aes(age, prop,
                   colour = fct_reorder2(marital, age, prop))) +
  geom_line(na.rm = TRUE) +
  labs(colour = "Marital", y = "Prop", x = "Age")
```

So we re-order the colour key to match proportions at top of age range and re-label the axis for clarities sake.

### Re-ordering with bar-plots
```{r}
gss_cat %>%
  mutate(marital = marital %>% fct_infreq() %>% fct_rev()) %>%
  ggplot(aes(marital)) +
    geom_bar()
```


### Exercises 15.4.1
#### 1. TV hours
```{r}
gss_cat %>% 
ggplot(aes(relig, tvhours)) +
  geom_boxplot() +
  coord_flip()

gss_cat %>% 
ggplot(aes(relig, tvhours)) +
  geom_jitter() +
  coord_flip()
```
If we change the mean to median the interpretation of the data is completely different. Can change the religion summary from mean to median to demonstrate this.

#### 2. levels of gss_cat
Examining the levels i.e. arbitrary or principled in this data set.

```{r}
levels(gss_cat$rincome)
levels(gss_cat$marital)
```
So the reported income is ordered logically, but the martial status could be ordered in many ways.

## Modifying Factor Levels
The most powerful tool for this is fct_recode. 
Allows to clarify labels, collapse levels i.e. income in gss

```{r}
gss_cat %>% count(partyid)
```
So we can change this so that it's sensible

```{r}
gss_cat %>%
  mutate(partyid = fct_recode(partyid,
    "Republican, strong"    = "Strong republican",
    "Republican, weak"      = "Not str republican",
    "Independent, near rep" = "Ind,near rep",
    "Independent, near dem" = "Ind,near dem",
    "Democrat, weak"        = "Not str democrat",
    "Democrat, strong"      = "Strong democrat"
  )) %>%
  count(partyid)
```
Then we can lump together the others, you couldn't label these NAs, but you could do this. You can also lump together in a string (shown second code chunk.)
```{r}
gss_cat %>%
  mutate(partyid = fct_recode(partyid,
    "Republican, strong"    = "Strong republican",
    "Republican, weak"      = "Not str republican",
    "Independent, near rep" = "Ind,near rep",
    "Independent, near dem" = "Ind,near dem",
    "Democrat, weak"        = "Not str democrat",
    "Democrat, strong"      = "Strong democrat",
    "Other"                 = "No answer",
    "Other"                 = "Don't know",
    "Other"                 = "Other party"
  )) %>%
  count(partyid)

gss_cat %>%
  mutate(partyid = fct_collapse(partyid,
    other = c("No answer", "Don't know", "Other party"),
    rep = c("Strong republican", "Not str republican"),
    ind = c("Ind,near rep", "Independent", "Ind,near dem"),
    dem = c("Not str democrat", "Strong democrat")
  )) %>%
  count(partyid)
```

### Lumping together small groups
```{r}
gss_cat %>% 
  mutate(relig = fct_lump(relig)) %>% 
  count(relig)
```
This works by lumping together the smallest groups until the aggregate is still the smallest group. In thise case it has lumped too many categories together. You can set the number of lumped categories as below, which works better in this case.

```{r}
gss_cat %>% 
  mutate(relig = fct_lump(relig, n = 5)) %>% 
  count(relig)
  
```

### Exercises 15.5.1
#### 1. 
To map proportions of partyid over time, put time on the x axis and collapsed as a proportion on the y axis.

```{r}
party_time <- gss_cat %>%
  group_by(year) %>% 
  mutate(partyid = fct_collapse(partyid,
    other = c("No answer", "Don't know", "Other party"),
    rep = c("Strong republican", "Not str republican"),
    ind = c("Ind,near rep", "Independent", "Ind,near dem"),
    dem = c("Not str democrat", "Strong democrat")
  )) %>%
  count(partyid) %>% 
  mutate(prop = n() / sum(n))

ggplot(party_time, aes(x = year, y = prop, colour = partyid)) +
  geom_line()
```
??Why does this only show republicans????

#### 2. Collapsing income into a small set of categories
Could either roll the little ones with lump, or use collapse to decrease the size of the levels. I would suggest widening each reported income bracket.

# Dates and Times
Dates and times aren't easy.
Not all days have 24 hours. Not all years have 365 days. Not all months have the same days.
We use lubridate here.

There are three types of date time data:
  - Date
  - Time
  - Date-Time
  
There is a package called HMS for just times.

You should always use the simplest package to meet your needs, if you only need dates, don't worry about times.

You can find the date and time with.
```{r}
today()
now()
```
Three ways to create a date time
  -String
  -From individual components
  -From existing date/time
  
## From strings
```{r}
ymd("2017-01-31")
mdy("January 31st, 2017")
ymd(20170131)
```
This shows that we are getting the date from 3 difference strings. When parsing the string like above you are stipulating where the y, m, and d is in the string. Meaning that date recording format i.e. American v rest of the world doesn't matter so much.

Dates times:

```{r}
ymd_hms("2017-01-31 20:11:59")
ymd_hms("2017-01-31 20:11:59", tz = "Pacific/Auckland")
```
The same quirk of stipulating the order of characters in the string applies here. Can change order of d,m,y and h,m,s (Where h,m,s means Hours, Minutes, Seconds.) Can also stipulate time zones.

```{r}
flights %>% 
  select(year,month, day, hour, minute) %>% 
  mutate(departure = make_datetime(year, month, day, hour, minute))
```
Recalling the modular decomposition of the weird time recordings in the flights dataset from previous workshops
```{r}
make_datetime_100 <- function(year, month, day, time) {
  make_datetime(year, month, day, time %/% 100, time %% 100)
}

flights_dt <- flights %>% 
  filter(!is.na(dep_time), !is.na(arr_time)) %>% 
  mutate(
    dep_time = make_datetime_100(year, month, day, dep_time),
    arr_time = make_datetime_100(year, month, day, arr_time),
    sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),
    sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)
  ) %>% 
  select(origin, dest, ends_with("delay"), ends_with("time"))

flights_dt
```
In this code we create a function, something we haven't covered yet. but we have covered the use of modular maths to decompose the hour and mins storage in this case.

This can be visualised. Can comment in code chunks with #
The below visulatisation shows the flights per day over time.

```{r}
flights_dt %>% 
  ggplot(aes(dep_time)) + 
  geom_freqpoly(binwidth = 86400) # 86400 seconds = 1 day
```

Flights within a day:

```{r}
flights_dt %>%
  filter(dep_time < ymd(20130102)) %>% 
  ggplot(aes(dep_time)) +
  geom_freqpoly(binwidth = (10*60)) #this is the binwidth for 10 minutes in seconds
  
```

as_datetime allows you to switch from date to datetime
```{r}
today()
as_datetime(today())
```
can also go backwards with as_date
```{r}
now()
as_date(now())
```
### Exercises  16.2.4
#### 1. Parsing string with invalid dates
```{r}
ymd(c("2010-10-10", "bananas"))
```
Causes a failure to parse.

#### 2. What does the tzone argument do to today()? Why is it important?
```{r}
?today()
```

tzone	
a character vector specifying which time zone you would like the current time in. tzone defaults to your computer's system timezone. You can retrieve the current time in the Universal Coordinated Time (UTC) with now("UTC").

This means that using today() and now() could be problematic if working with people in different time zones as it relies on the time zone of the local computer.

#### 3. Parsing the following date time strings
```{r}
d1 <- "January 1, 2010"
d2 <- "2015-Mar-07"
d3 <- "06-Jun-2017"
d4 <- c("August 19 (2015)", "July 1 (2015)")
d5 <- "12/30/14" # Dec 30, 2014

mdy(d1)
ymd(d2)
dmy(d3)
mdy(d4)
mdy(d5)
```

The format to use depends on your use case.

## Date time components

This code shows you calling specific values from the date time
```{r}
datetime <- ymd_hms("2016-07-08 12:34:56")

year(datetime)
month(datetime)
mday(datetime)
yday(datetime)
wday(datetime)


```
yday is days since 1/jan. wday is number day of week.
can use months as labels, and change if they're abbreviated or not with T/F arguments.

```{r}
flights_dt %>% 
  mutate(wday = wday(dep_time, label = TRUE, abbr = FALSE)) %>% 
  ggplot(aes(x = wday)) + 
  geom_bar()
```

## Rounding
You can round dates three ways:
-   Floor(down)
-   Ceiling (up)
-   Round_date (round to)

## Time spans
There are three classes
-   Duration (exact number of seconds)
-   Periods (human units, i.e. weeks and months)
-   Intervals (represents start and end point)
They all have the uses, duration is most accurate, but not useful if trying to cumulate into months.

### Durations

This uses the authors age to illustrate durations of lubridate.

```{r}
h_age = today() - ymd(19791014)
h_age

class(h_age)

as.duration(h_age)
```

You can also could seconds (maths) in various time units
```{r}
dseconds(15)
dhours(23)
dweeks(12)
```
### Periods

Lubridate provides periods (human time spans) but don't have a fixed length in seconds.

Lets use periods to fix the flights data set, which was showing some flights going back in time due to being over night flights.
```{r}
flights_dt %>% 
  filter(arr_time < dep_time)

flights_dt <- flights_dt %>% 
  mutate(
    overnight = arr_time < dep_time,
    arr_time = arr_time + days(1 * overnight),
    sched_arr_time = sched_arr_time + days(1 * overnight)
  )
```
### Intervals

```{r}
dyears(1) / ddays(365)
```
Quirk of these is not exactly 1 due to the way time is recorded (daylight savings, leap years etc)

If you want a more accurate measurement, youâ€™ll have to use an interval. An interval is a duration with a starting point: that makes it precise so you can determine exactly how long it is:

### Summary

If you are getting errors after trying to maniuplate time, perhaps you have specified something correctly.

### Exercises 16.4.5

#### 1. Why is there months() but not dmonths()
Not every month has the same number of days, and thus seconds.

#### 2. Explain (overnight * 1)
We created a binary (0,1) variable for flights that occur overnight. When true = 1, which can be used to manipulate time to account for overnight flights.

#### 3.
Creating a vector of dates for every first day of the month in 2015 (in a code efficient way)

```{r}
ymd("2015-01-01") + months(0:11)
```

## Time Zones

R can use consistent time zones from IANA in the format "Continent/City"

Can check your current time zone in R.
```{r}
Sys.timezone()
```
There are 593 timezones, they can be found with OlsonNames()
Time zone is an attribute of the date time, but only controls printing.

These times are the same, can verify by subtracting.
```{r}
(x1 <- ymd_hms("2015-06-01 12:00:00", tz = "America/New_York"))
(x2 <- ymd_hms("2015-06-01 18:00:00", tz = "Europe/Copenhagen"))
(x3 <- ymd_hms("2015-06-02 04:00:00", tz = "Pacific/Auckland"))

x1-x2
x2-x3

x4 <- c(x1, x2, x3)
x4

```
You can change the time zone if entered incorrectly in the data via 
```{r}
x4 <- c(x1, x2, x3)
x4
x4a <- with_tz(x4, tzone = "Australia/Lord_Howe")
x4a
x4a - x4

x4b <- force_tz(x4, tzone = "Australia/Lord_Howe")
x4b
x4b <- force_tz(x4, tzone = "Australia/Lord_Howe")
x4b

x4a-x4b
```

